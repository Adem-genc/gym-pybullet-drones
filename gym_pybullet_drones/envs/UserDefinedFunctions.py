import os
import time
import pdb
import math
import numpy as np
import pybullet as p
import gym
from gym import error, spaces, utils
from gym.utils import seeding






######################################################################################################################################################
#### A class for user-defined "reward" and "done" functions ##########################################################################################
######################################################################################################################################################


class UserDefinedFunctions(object):

    ####################################################################################################
    #### TBD ####################################################################
    ####################################################################################################
    def __init__(self):
        pass

    ####################################################################################################
    #### Compute the current state's reward ############################################################
    ####################################################################################################
    #### Arguments #####################################################################################
    #### - norm. state (20-by-1 array)      clipped and normalized simulation state ####################
    ####################################################################################################
    #### Returns #######################################################################################
    #### - reward (Float)                   reward value ###############################################
    ####################################################################################################
    def _computeReward(self, state):
        ####################################################################################################
        #### Customize the reward function #################################################################
        ####################################################################################################
        if state[2] > 0.8: reward = -1
        elif state[2] > 0.5: reward = 2000
        elif state[2] > 0.3: reward = 1000
        elif state[2] > 0.2: reward = 500
        elif state[2] > 0.15: reward = 100
        elif state[2] > 0.1: reward = 10
        else: reward = -1
        ####################################################################################################
        ####################################################################################################
        return reward

    ####################################################################################################
    #### Evaluate the current state's halting conditions ###############################################
    ####################################################################################################
    #### Arguments #####################################################################################
    #### - norm. state (20-by-1 array)      clipped and normalized simulation state ####################
    ####################################################################################################
    #### Returns #######################################################################################
    #### - done (Boolean)                   whether the halting conditions of the episode are met ######
    ####################################################################################################
    def _isDone(self, state):
        ####################################################################################################
        #### Customize the episodes' halting conditions ####################################################
        ####################################################################################################
        if np.abs(state[0])>=1 or np.abs(state[1])>=1 or state[2]>=1 \
                    or np.abs(state[7])>=np.pi/3 or np.abs(state[8])>=np.pi/3 \
                    or np.abs(state[10])>=1 or np.abs(state[11])>=1 or np.abs(state[12])>=1 \
                    or np.abs(state[13])>=10*np.pi or np.abs(state[14])>=10*np.pi or np.abs(state[15])>=20*np.pi \
                    or self.step_counter > 3*self.SIM_FREQ: 
            done = True
        else: 
            done = False
        ####################################################################################################
        ####################################################################################################
        return done